# Default values for nussknacker.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: touk/nussknacker
  tag: staging-latest
  pullPolicy: IfNotPresent

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

podSecurityContext:
  fsGroup: 1001

securityContext:
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  runAsUser: 1001

service:
  type: ClusterIP
  port: 80

persistence:
  enabled: true
  ## A manually managed Persistent Volume and Claim
  ## If defined, PVC must be created manually before volume will be bound
  ## The value is evaluated as a template, so, for example, the name can depend on .Release or .Chart
  ##
  # existingClaim:

  ## The subdirectory of the volume to mount to, useful in dev environments
  ## and one PV for multiple services.
  ##
  subPath: ""

  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"

  accessMode: ReadWriteOnce
  size: 1Gi
  annotations: {}

ingress:
  enabled: true
  annotations: 
    certmanager.k8s.io/cluster-issuer: "letsencrypt-prod"
  domain: carpinion.touk.pl
  # host: .Release.Name-nussknacker
  # tlsSecretName: .Release.Name-nussknacker-tls

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

postgresql:
  enabled: true
  volumePermissions:
    enabled: true

kafka:
  enabled: true

schema-registry:
  enabled: true
  kafka:
    enabled: false

schema-registry-ui:
  enabled: true
  schema-registry:
    url: http://{{ .Release.Name }}-schema-registry
    port: 8081
    proxy: true

flink:
  enabled: true
  taskmanager:
    statefulset: false
  jobmanager:
    statefulset: true
  prometheus:
    serviceMonitor:
      enabled: false

elasticsearch:
  enabled: true

kibana:
  enabled: true
  env:
    ELASTICSEARCH_HOSTS: http://{{ .Release.Name }}-elasticsearch-client:9200


logstash:
  enabled: true
  inputs:
    main: |-
      input {
        kafka {
        codec => "json"
        bootstrap_servers => "http://master-kafka.nk-cloud-1251-master.k8s-carpinion.touk.pl:9092"
        # topics_pattern => ".*"
        # topics => ["test.input", "test.test"]
        auto_offset_reset => "latest"
        client_id => "logstash"
        group_id => "logstash"
        decorate_events => "true"
        }
      }
  filters:
    main: |-
      filter {
        if [eventTime] {
          date {
            match => [ "eventTime", "ISO8601" ]
            target => [ "parsedEventTime" ]
          }
        }
        mutate {
          add_field => { "topic" => "%{[@metadata][kafka][topic]}"}
        }
      }
  outputs:
    main: |-
      output {
        elasticsearch {
          index => "events.%{[@metadata][kafka][topic]}-%{+YYYY.MM}"
          hosts => ["http://master-elasticsearch-client.nk-cloud-1251-master.k8s-carpinion.touk.pl:9200"]
        }
      }   
  elasticsearch:
    host: http://master-elasticsearch-client.nk-cloud-1251-master.k8s-carpinion.touk.pl


grafana:
  enabled: true

influxdb:
  enabled: true
